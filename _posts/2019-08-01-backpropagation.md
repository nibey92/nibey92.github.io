---
layout: post
title: Back Propagation
excerpt: "역전파 이해하기"
categories: [deep learning]
comments: true
---

주로 참고한 블로그 글은 다음과 같습니다.
{: .notice}
 
 > [UMBUM](https://umbum.tistory.com/222)

## Neural Network Overview
예제를 위해 사용될 인공 신경망은 앞에서 소개한 사이트의 모델과 같은 것을 사용합니다. 이 인공 신경망은 입력층, 은닉층, 출력층 3개의 층을 가집니다. 또한 각 층에는 두개의 뉴런이 있습니다. 은닉층과 출력층의 모든 뉴런은 시그모이드 함수를 활성화 함수로 사용합니다.
![propa]({{ site.url }}/img/propa.PNG)

#### 은닉층
* W : 입력층에서 은닉층 방향으로 향하는 가중치 입니다.
* z : 입력층의 x 값에 가중치 W가 곱해진 값입니다.
* h : z 값이 시그모이드 함수를 지난 후 값으로 은닉층의 출력값입니다.

#### 출력층
* U : 은닉층에서 출력층 방향으로 향하는 가중치 입니다.
* t : 은닉층의 출력값 h에 가중치 U가 곱해진 값입니다.
* o : t 값이 시그모이드 함수를 지난 후의 값으로 출력층의 출력값입니다.
 
이번 역전파 예제에서는 인공 신경망에 존재하는 모든 가중치 W와 U에 대해서 역전파를 통해 업데이트하는 것을 목표로 합니다. 해당인공 신경망은 편향 b는 고려하지 않습니다.

## Forward Propagation


