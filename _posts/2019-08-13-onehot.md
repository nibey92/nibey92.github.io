---
layout: post
title: One-hot encoding
excerpt: "One-hot encoding에 대해 알아보고 간단한 코드로 구현해 봅니다."
categories: [preprocessing]
comments: true
---

컴퓨터는 문자보다는 숫자를 더 잘 인식합니다. 특히 문자를 많이 다루는 자연어처리에서 문자를 숫자로 바꾸는 기법을 사용 하는데 One-hot encoding은 가장 기본적인 기법이며 머신러닝, 딥러닝에서 자주 사용하는 방법입니다. 시작하기 앞서 이번 글은 [딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/22647) 의 `원-핫 인코딩` 글을 공부하고 그 내용을 제 나름대로 풀어 쓴 것임을 밝힙니다.

## One-hot encoding
원-핫 인코딩을 위해서 먼저 해야할 일은 갖고 있는 우선 단어 집합을 만드는 일입니다. 텍스트의 모든 단어를 중복을 허락하지 않고 모아놓는다면 이를 `단어 집합(Vocabulary)`이라고 합니다. 단어 집합은 자연어처리에서 계속해서 등장하는 개념입니다. 단어 집합은 한마디로 서로 다른 단어들의 집합입니다. 예를들어 사과, 바나나, 딸기의 집합이 있다면 단어 집합의 크기는 3 입니다. 단어 집합에서는 book과 books와 같이 단어의 변형 형태도 다른 단어로 간주합니다.

그 다음으로는 이 단어 집합의 단어들마다 0번부터 2번까지의 인덱스를 부여합니다. 사과는 0번, 바나나는 1번, 딸기는 2번과 같이 부여됩니다. 이러한 과정을 `정수인코딩(Integer encoding)`이라고 합니다. 이렇게 단어들 모두에 대해서 인덱스를 부여하고 나면 각 단어에 해당하는 인덱스에 1의 값을 부여하고 다른 인덱스에는 0을 부여하여 단어를 벡터로 표현할 수 있습니다. 이렇게 표현된 벡터를 원-핫 벡터(One-hot vector)라고 합니다. 아래의 그림을 참고하면 이해하기 쉽습니다.

## Keras로 구현하기
케라스에서는 자동으로 원-핫 인코딩을 만들어주는 to_categorical()를 지원합니다. 케라스만으로 정수 인코딩과 원-핫 인코딩을 순차적으로 진행해보도록 하겠습니다.

### 정수 인코딩
{% highlight ruby %} 
text="나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야"
{% endhighlight %}

위와 같은 문장이 있다고 했을 때, 정수 인코딩 챕터에서 배운 케라스의 토크나이저 도구를 이용한 정수 인코딩(인덱스 부여)을 진행하면 다음과 같습니다.
{% highlight ruby %} 
text="나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야"
from keras_preprocessing.text import Tokenizer
t = Tokenizer()
t.fit_on_texts([text])
# 입력으로 [text]가 아닌 text를 넣을 경우 한 글자 단위 인코딩이 되버립니다. ex 갈 : 1, 래 : 2
print(t.word_index) # 각 단어에 대한 인코딩 결과 출력.
{% endhighlight %}

{% highlight ruby %} 
{'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}
{% endhighlight %}
와 같이 생성된 단어 집합(Vocabulary)에 있는 단어들로만 구성된 텍스트가 있다면, texts_to_sequences()를 통해서 이를 바로 인덱스의 나열로 변환가능합니다. 생성된 단어 집합의 단어들로만 구성된 서브 텍스트 text2를 가지고 확인해보겠습니다.

{% highlight ruby %} 
text2="점심 먹으러 갈래 메뉴는 햄버거 최고야"
x=t.texts_to_sequences([text2])[0]
print(x)
{% endhighlight %}

### 원-핫 인코딩 
지금까지 진행한 것은 이미 정수 인코딩 챕터에서 배운 정수 인코딩 과정입니다. 이제 해당 결과를 가지고, 원-핫 인코딩을 진행해보도록 하겠습니다. 케라스는 정수 인코딩 된 결과를 입력으로 받아 바로 원-핫 인코딩 과정을 수행하는 to_categorical()를 지원합니다.

{% highlight ruby %} 
vocab_size = len(t.word_index) # 단어 집합의 크기. 이 경우는 단어의 개수가 7이므로 7.

from keras.utils import to_categorical
x = to_categorical(x, num_classes=vocab_size+1) # 실제 단어 집합의 크기보다 +1로 크기를 만들어야함.

print(x)
{% endhighlight %}

{% highlight ruby %} 
[[0. 0. 1. 0. 0. 0. 0. 0.] #인덱스 2의 원-핫 벡터
 [0. 0. 0. 0. 0. 1. 0. 0.] #인덱스 5의 원-핫 벡터
 [0. 1. 0. 0. 0. 0. 0. 0.] #인덱스 1의 원-핫 벡터
 [0. 0. 0. 0. 0. 0. 1. 0.] #인덱스 6의 원-핫 벡터
 [0. 0. 0. 1. 0. 0. 0. 0.] #인덱스 3의 원-핫 벡터
 [0. 0. 0. 0. 0. 0. 0. 1.]] #인덱스 7의 원-핫 벡터
{% endhighlight %}

여기서 주의할 점은 to_categorical()은 정수 인코딩으로 부여된 인덱스를 그대로 배열의 인덱스로 사용하기 때문에, t.fit_on_texts()를 사용하여 정수 인코딩을 하였을 경우에는 실제 단어 집합의 크기보다 +1의 크기를 인자로 주어야 한다는 점입니다. t.fit_on_texts()는 인덱스를 1부터 부여합니다. 하지만 배열의 인덱스는 0부터 시작하므로 맨 마지막 인덱스를 가진 단어의 인덱스가 7인데, 이를 원-핫 벡터로 만들기 위해서는 총 8의 크기를 가진 배열이 필요합니다.

위의 결과는 "점심 먹으러 갈래 메뉴는 햄버거 최고야"라는 문장이 [2, 5, 1, 6, 3, 7]로 정수 인코딩이 되고나서, 각각의 인코딩 된 결과를 인덱스로 원-핫 인코딩이 수행된 모습을 보여줍니다.
