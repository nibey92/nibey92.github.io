---
layout: post
title: Regression
excerpt: "Linear regression"
categories: [machine learning]
comments: true
---

이 포스팅은 `KMOOC 자율주행을위한 머신러닝 강좌`를 청강한 후 정리하였습니다.
{: .notice}

딥러닝을 이해하기 위해서는 Linear Regression과 Logistic Regression을 이해할 필요가 있습니다. 오늘은 우선 선형회귀에 대해서 알아보겠습니다. 선형회귀 개념 자체에 대한 이해도 중요하지만 머신러닝에서 쓰이는 용어인 가설, 손실함수, 경사하강법에 대한 개념까지 함께 이해하도록 하겠습니다.

## Linear regression

시험 공부 시간이 늘어날수록 성적이 잘 나오고 운동시간을 늘릴수록 몸무게는 줄어듭니다. 집의 평수가 클수록 집의 매매 가격은 비싼 경향이 있습니다. 수학적으로 생각해보면 어떤 요인의 수치가 특정 수치에 영향을 주고있습니다. 다른 변수의 값을 변하게 하는 변수를 ``x``, 변수 x에 의해 값이 종속적으로 변하는 변수를 ``y``라고 합니다. 

선형 회귀는 종속 변수 y와 한 개 이상의 독립 변수 x 와의 선형 관계를 모델링하는 분석 기법입니다. 즉 x는 1개일수도, 그 이상일 수도 있습니다. 독립변수 x가 1개일 때 단순 선형 회귀라고 합니다.


### Simple Linear Regression Analysis



집의 크기에 따른 집값을 생각 해 봅시다. 집의 크기를 x, 집값이 y라 하면 수식은 다음과 같이 나타낼 수 있습니다.

* $$y = Wx + b$$ 

위의 수식은 단순선형회귀(Simple Linear Regression Analysis)의 수식을 보여줍니다. 여기서 W를 ``가중치(weight)``, b를 ``편향(bias)`` 이라고 합니다.

단순선형회귀에서는 x의 개수가 '집의크기' 1개입니다. 그래프에서

### Multiple Linear Regression Analysis

* $$ y = W_1x_1 + W_2x_2 + .... W_nx_n +b $$

잘 생각해보면 집값은 집의 크기 뿐만이 아니라 집의 층수, 집이 지어진 연도, 역과의 거리 등의 요소들도 영향을 미칩니다. 이렇게 다수의 요소를 가지고 집의 가격을 예측해 봅시다. y는 여전히 1개이지만 x는 이제 여러개가 되었습니다. 이를 다중 선형 회귀 분석(Multiple Linear Regression Analysis)이라고 합니다.

### feature, sample

위에서 보았던 단순선형회귀 분석과 다중선형회귀 분석을 생각해 봅시다. 단순성형회귀 분석에서 x의 정보는 '집의크기' 였습니다. 이때 이 '집의크기'는 하나의 ``feature``라고 합니다. 다중선형회귀 분석에서 집값을 결정하는 요인으로 집의 크기, 집의 층수, 집이 지어진 연도, 역과의 거리 4개를 사용한다고 하면 feature의 개수는 총 4개 입니다.

``sample``은 x와 y 한 세트를 의미합니다. 첫번째 집의 정보가 $$ X_1 = (x_{1,집의크기}, x_{1,집의 층수}, x_{1,집이 지어진 연도}, x_{1,역과의 거리})$$이고 가격 $$ Y_1 = {y_1} $$ 로 주어지면 이것을 한 sample이라고 합니다. 이런 식으로 총 몇개의 집이 주어지는지에 따라 sample의 개수가 결정되겠죠.  

## Matrix

아래 그림을 봅시다 좌표의 개수는 (1,2), (2,4), (4,3) (5,4) 총 네개가 있습니다. 이차좌표평면이고 집값을 결정하는 x 요인은 하나이므로 feature의개수는 한개 입니다. 
