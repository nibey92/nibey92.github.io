---
layout: post
title: SVM, Support Vector Machine
excerpt: "SVM 개념과 수식원리를 알아봅시다."
categories: [machine learning]
comments: true
---


오늘은 딥러닝이 생기기 이전 기계학습 분야에서 가장 널리, 유명하게 쓰였던 `Support Vector Machine`에 대해서 알아보도록 하겠습니다. `SVM`을 제대로 이해하기 위해서는 이와 관련된 수학적인 기법들 (Lagrangian, Daul problrem, KKT) 을 우선적으로 이해하여야 합니다. 하지만 이것들을 모르더라도 전체적인 `SVM`에 대한 개략적인 방법을 설명하도록 하겠습니다. 

## Idea

`SVM`이 가장 큰 성능을 내는 것은 분류문제 입니다. 어떻게 분류할 것인가 하는것은 기계학습에 가장 기본적인 문제이기도 하죠. 여기 두 집단의 데이터가 있습니다. $$+$$와 $$-$$ 집단입니다. 두 집단을 잘 구분하는 선은 둘 중 어느 선일까요?
![graph]({{ site.url }}/img/svm-1.PNG)

대다수의 분들이 1번이라고 할 것입니다. 그 이유는 1번선이 2번선에 비해서 두 집단을 좀 더 여유롭게 분류하고 있기 때문이죠. 이 때 이 여유로운 공간을  `Margin` 이라고 합니다. 그리고 `SVM`은 `margin`을 최대화 하는 분류 경계면을 찾는 기법이라고 할 수 있습니다. 

![graph]({{ site.url }}/img/svm-2.PNG)

## Decision rule

개념적으로 `SVM`이 어떻게 작동하는지 알아보았습니다. 하지만 늘 그렇듯, 언어로 이해하기는 쉽지만 수학적으로 풀어내기는 쉽지 않죠. `Margin`을 최대화하는 분류 경계면을 찾기 위해 우리는 수학적인 식들을 찾아야 합니다. 먼저 우리가 찾는 분류 경계선이 있을 때 이 경계선이 $$+$$와 $$-$$를 어떻게 구분하는지 `desision rule`을 정해봅시다. 

먼저 분류 경계면에 대해 수직인 벡터 $$\vec{w}$$ 를 정의 합니다. 그리고 각 데이터에 대한 벡터 $$\vec{x}$$에 대해 $$\vec{w}$$를 내적하고 이 값이 어떤 상수보다 크면 $$+$$, 작으면 $$-$$로 분류할 수 있습니다. 여기서 내적을 함으로써 $$\vec{w}$$ 방향으로 $$\vec{x}$$ 를 `projection` 한다는 의미가 있습니다. 이를 수식으로 쓰면 다음과 같이 쓸 수 있겠죠

![graph]({{ site.url }}/img/svm-3.PNG)


* $$ \vec{w} \cdot \vec{x} > b$$ $$\quad then \;+ $$
* $$ \vec{w} \cdot \vec{x} < b$$ $$\quad then \;- $$

사실 이것은 아직 `SVM`의 식은 아닙니다. `SVM`의 특징인 `margin`를 첨가해야 겠죠. 또한 이렇게 만들어지는 식의 미지수인 $$\vec{w}$$와 $$b$$도 정하지 못했습니다. 우리가 아는 것은 $$\vec{w}$$가 분류경계면과 수직이라는 사실 뿐입니다. 기본적인 식에 조건이나 제약을 추가하여 $$\vec{w}$$와 $$b$$를 찾아가는 것이 이번 시간에 해야할 목표가 되겠습니다. 

## Boundary 정의

이제부터 `SVM`에 필요한 식을 만들어 봅시다. 먼저 `decision rule`을 참고하여 $$\vec{w}$$와 $$\vec{x}$$를 내적하고 상수 $$b$$를 더한 값이 `0`일때를 `분류경계면`으로 설정합시다. 

* $$ \vec{w} \cdot \vec{x} + b = 0$$ $$\quad then \;Boundary $$

그럼 수식의 값이 0보다 크면 $$\vec{x}$$를 $$+$$로 분류해야 할까요? 아직은 판단하기 이릅니다. `SVM`에서는 `margin` 영역이 있습니다. $$\vec{x_+} $$와 $$\vec{x_-} $$ 어느 데이터도 들어 있지 않은 구간이죠. 이 구간을 정해줍시다.

* $$\vec{w} \cdot \vec{x} + b = +1$$  $$\quad then \quad Plus \; boundary$$
* $$\vec{w} \cdot \vec{x} + b = -1$$  $$\quad then \quad Minus \; boundary$$

위 식에서 경계선을 각각 $$1$$과 $$-1$$로 둔 것은 경계면 길이를 $$1$$로 `normalization` 했다고 볼 수 있습니다. 이 세개의 경계면에 대한 식을 그림으로 나타내면 아래와 같습니다. 그림을 보시면 한결 이해하기 편할 겁니다. 

![graph]({{ site.url }}/img/svm-4.PNG)

## 제약식의 정의

앞에서 `boundary`를 정의하는 식을 보았습니다. 이제 실제 데이터가 있는 공간 `Plust plane`과 `Minus plane`에 속해있는 데이터 벡터들 $$\vec{x_+}$$와 $$\vec{x_-}$$를 가지고 제약식을 정의해 보도록 하겠습니다. 참고로 우리는 Lagrange 식을 이용하여 SVM을 풀어갈 것입니다. Lagrange 문제에서는 목적식과 제약식이 필요합니다. 따라서 이 중에서 제약식을 먼저 정의하도록 하겠습니다. 

위에서 정한 boundary를 기준으로 생각하면  plus data vector $$\vec{x_+}$$ 들은 plus boundary 위에 있어야 할 것이고 minus data vector $$\vec{x_-}$$들이 있는 있는 공간은 minus boundary 아래에 위치해야 겠죠. 따라서 이것을 식으로 그대로 쓰면 다음과 같이 쓸 수 있겠습니다. 

* $$ \left\{\begin{matrix}
 & \vec{w} \cdot \vec{x_+} + b \geq +1 & \\ 
 & \vec{w} \cdot \vec{x_+} + b \leq -1 & 
\end{matrix}\right. $$

그런데 이렇게 데이터 x에 관한 식을 쓰고 나니 두개의 식이 되었습니다. 계산의 편의를 위해서 두개의 식을 하나의 식으로 표현하기 위해서 아래와 같이 정의된 $$y_i$$를 도입하도록 하겠습니다. 

* $$ y_i =$$  $$\left\{\begin{matrix}
 &1  & for  +\\ 
 &-1 & for  -
\end{matrix}\right.$$

앞선 두 식의 양 변에 $$y_i$$를 곱해줍니다. 그럼 $$y_i$$가 $$+$$ 식에서는 $$+1$$, $$-$$ 식에서는 $$-1$$이기 떄문에 아래와 같이 식을 정리할 수 있습니다. 

![graph]({{ site.url }}/img/svm-6.JPG)

이렇게 해서 제약식을 얻었습니다. 

![graph]({{ site.url }}/img/svm-7.JPG)

![graph]({{ site.url }}/img/svm-8.JPG)
