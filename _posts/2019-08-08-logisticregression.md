---
layout: post
title: Logistic regression
excerpt: "Logistic regression"
categories: [machine learning]
comments: true
---

이번 글은 [딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/37406) 의 ``로지스틱 회귀`` 글을 공부하고 그 내용을 제 나름대로 풀어 쓴 것입니다.
> [딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/37406)

## Binary Classifiaction

선형회귀 챕터에서 집크기와 집값의 관계를 직선의 방정식으로 표현한다는 가설 하에 주어진 데이터로부터 가중치 W와 편향 b를 찾아 데이터를 가장 잘 표현하는 직선을 찾았습니다. 그런데 이번에 배울 둘 중 하나의 선택지 중에서 정답을 고르는 이진 분류 문제는 직선으로 표현하는 것이 적절하지 않습니다.

예를 들어 아래 표와같이 여러 학생의 시험 성적에 따른 합격 결과 데이터를 가정해 봅시다. 시험성적이 x라면 시험결과는  y 입니다. 이 데이터로부터 특정 점수를 얻었을 때의 합격, 불합격 여부를 알기 위해서는 어떻게 해야 할까요?

![graph]({{ site.url }}/img/logistic-1.PNG)

왼쪽은 데이터이고 오른쪽은 데이터를 그래프로 그려본 것입니다. 합격 결과는 1, 불합격은 0으로 두었습니다. 두가지 값에 대해 다른 숫자를 사용해도 가능은 하지만 이진분류 에서는 보편적으로 0과 1 을 사용합니다. 그래프에서 보듯이 이진분류에서 그래프는 아라파벳의 S 자 형태로 표현됩니다. 직선을 사용 할 경우 이 데이터들을 제대로 나타내지 못해 분류작업이 제대로 동작하지 않는 경우가 많습니다.

또한 이진분류에서는 실제값 y가 보통 0 또는 1이라는 두가지 값만을 가집니다. 이 문제를 풀기 위해서 예측값 $$\hat{y}$$ 는 0에서 1 사이의 값을 가지도록 하는 것이 보편적입니다. 왜냐하면 0과 1사이의 값은 확률로 해석할 수 있기 때문입니다. 하지만 선형 회귀의 경우 y값이 음의 무한대부터 양의 무한대와 같은 큰 수들도 가질 수 있는데 이 또한 직선이 분류 문제에 적합하지 않은 이유라 할 수 있습니다.

자 이제 0과 1 사이의 값을 가지면서 S자 형태로 그려지는 조건을 충족하는 함수를 찾아야 합니다. 사실 이 조건들을 충족하는 유명한 함수가 있는데 바로 시그모이드(Sigmoid) 함수입니다. 시그모이드는 딥러닝에서 아주 중요한 함수이고 이를 제대로 이해하고 가는 것이 좋습니다.

## Sigmoid function

우선 시그모이드 함수의 방정식은 아래와 같습니다. 종종 $$\sigma$$로 표현하기도 합니다.

* $$ H(x) = frac{1}{1+e^{-(Wx+b)}} = sigmoid(Wx+b) = \sigma(Wx+b) $$

![graph]({{ site.url }}/img/logistic-2.PNG)

여기서 e(e=2.718281)는 자연상수 입니다. 여기서 구해야 할 것은 여전히 주어진 데이터에 가장 적합한 가중치 W와 편향 bias입니다. 모든 인공지능 알고리즘이 하는 일은 결국 주어진 데이터에 대해 적합한 가중치 W와 b를 구하는 것입니다. 위의 시그모이드 그래프에서 보는것과 같이 x가 0일때는 0.5를 가지고 x가 증가하면 1에 수렴, 감소하면 0에 수렴합니다. 이 그래프에서 가중치 W와 편향 b가 어떤 의미를 가지는지 그래프를 통해 알아보겠습니다. 

![graph]({{ site.url }}/img/logistic-3.PNG)

W가 1일 때 초록색선이고 W 값이 0.5일때 빨간색, 2일때 초록색 선으로 표현하였습니다. W값에 따라 그래프의 경사도가 변하는 것을 볼 수 있습니다. W 값이 커지면 경사가 커지고 W 값이 작아지면 경사가 작아집니다.

이제  b 값에 따라 그래프가 어떻게 변하는지 확인해보도록 하겠습니다.

b 값이 커질 수록 그래프가 왼쪽으로 움직이고 작아지면 오른쪽으로 움직이는 것을 볼 수 있습니다.

지금까지 시그모이드 함수에 대해서 정리해보앗습니다. 시그모이드 함수는 입력값이 커지면 1에 수렴하고 입력값이 작아지면 0에 수렴합니다. 0부터 1까지의 값을 가지는데 출력값이 0.5 이상이면 1(True), 0.5 이하이면 0 (False)로 만들어 이진분류 문제에 사용할 수 있습니다.






