---
layout: post
title: Generative Adversarial Network, GAN
excerpt: "GAN의 개념을 이해하고 구현해보자"
categories: [GAN practice]
comments: true
---

2014년 Ian Goodfellow가 NPS에서 발표한 paper에서 시작한 GAN은 2016년에 특히 크게 떠올랐습니다. 

## GAN 개념적 소개

Generative Adversarial Network 라는 이름에서 알 수 있듯이 우선 ``Adversrial``는 ``대립``, ``적대``의 뜻을 지닙니다. GAN은 이렇게 서로 대립하는 두 부분으로 나누어져 있다는것을 짐작할 수 있습니다. 
GAN은 생성하는 ``Generator``와  Generator 가 만든 녀석을 평가하는 ``Discriminaotr``가 있고 서로 대립 (Adversarial) 하며 서로의 성능을 점차 개선해나갑니다. Ian Goofellow가 논문에서 이를 설명한 것이 유명하기도 하고 재미있기 때문에 소개합니다. 

> 지폐위조범(Generator)은 경찰을 최대한 열심히 속이려고 하고 다른 한편에서는 경찰(Discriminator)이 이렇게 위조된 지폐를 진짜와 감별하려고(Classify) 노력한다.
이런 경쟁 속에서 두 그룹 모두 속이고 구별하는 서로의 능력이 발전하게 되고 결과적으로는 진짜 지폐와 위조 지폐를 구별할 수 없을 정도(구별할 확률 $$p_d=0.5$$)에 이른다는 것.

이제 이 예시를 좀 더 구체적으로 얘기하면 다음과 같습니다. Generator G는 우리가 가지고 있는 data x의 distribution을 알아내려고 노력합니다. 만약 G가 정확히 data distribution을 모사할 수 있다면 그렇게 만들어진 sample은 data와 구별할 수 없을 정도로 같겠죠.
한편 discrimianor D는 현재 자기가 보고 있는 sample이 training data에서 온 것인지 G에서 만들어진 것인지 구별하여 각각 경우에 대한 확률을 측정합니다. 

![gan-1]({{ site.url }}/img/gan-1.PNG)

위 그림에서 볼 수 있듯이 최종 아웃풋은 D(s) 입니다. 이 때 s는 ``real data x``와 generator 에서 만들어진 ``G(z)`` 중 랜덤하게 골라진 sample 입니다. (s 라는 표기는 이해를 돕기 위해 제가 임의로 사용했고 실제 논문에는 사용하지 않았습니다.)

D의 입장에서는 만약 sample s 가 ``real data x`` 라면 ``D(x)=1``이 되도록 노력할 것이고 sample s 가 generator가 생성한 ``fake data G(z)`` 라면 ``D(G(z))=0`` 이 되도록 노력 할 것입니다. 즉, D는 실수할 확률을 낮추기 위해 (mini) 노력하고 반대로 G는 D가 실수할 확률을 높이기 (max) 위해 노력하는데, 따라서 둘을 같이 놓고 보면 **"minimax tow-player game of minimax problem"** 이라 할 수 있겠습니다. 

## Adversarial Nets

* Input noise varibales $$p_z(z)$$
* Generator's distribution over data x $$p_g$$
* Real data distribution $$p_{data(x)}$$

``Generator G``는 real data x 의 distribution을 학습하기 위해 input noise variable $$p_z(z)$$에 대한 prior을 정의하고 fake data를 만들어내기에 $$G(z;\theta_g)$$라 표현 할 수 있습니다. G는 미분 가능한 함수로써 $$\theta_g$$를 parameter로 갖는 multilayer perceptron 입니다.

``Discriminator D`` 역시 multilyaer perceptron으로 ``D(s;\theta_d)``로 나타내며 output은 확률이므로 signle scalar 값으로 나타내게 됩니다. 따라서 ``D(s)``는 s가 generator's distirbution $$p_g$$가 아닌 real data distribution $$p_x$$ 로부터 왔을 확률을 나타냅니다.

따라서 이를 수식으로 정리하면 다음과 같은 value function V(G,D)에 대한 minmax problem을 푸는 것과 같아집니다. 

* $$ min max V(D,G) = E_{x~P_{data}(x)}[logD(x)] + E_{z~P_{z}(x)}[1-D(G(z)))]$$ 

이 수식을 이해하기 위해서는 극단적인 예시를 넣어보면 좋습니다. 먼저 가장 이상적인 상황에서의 D를 생각해 봅니다. D는 아주 잘 구별을 하는 함수입니다. 그렇기에
* D가보는 sample s가 real data distriubtion에서 온 것이라면(s=x), D(x) = 1이므로 첫번째 term은 0이 됩니다.
* D가보는 sample s 가 G가 만들어낸 것이라면(s=G(z)), D(G(z)) = 0이므로 두번재 term 역시 0으로 사라집니다. 

따라서 이 때 D의 입장에서 V의 최대값을 얻을 수 있다는 것은 자명합니다. 

## 학습과정

이 그림은 위에 설명한 내용을 이해하기 좋게 잘 그려놓았습니다. 먼저 검정색 점선이 data generating distribution $$p_x$$, 파란 점선이 discriminator distribution, 녹색 선이 generative distribution $$p_g$$ 입니다. 밑에  선은 각각 x와 z의 domain을 나타내며, 위로 뻗은 화살표가 $$x=G(z)$$의 mapping을 보여줍니다. 

처음 시작할 때는 (a)와 같이 $$p_g$$와 $$p_{data}$$가 전혀 다르게 생긴 것을 볼 수 있고 이 상태에서 discriminator가 두 distribution을 구별하기 위해 학습을 하면 (b)와 같이 좀 더 smooth하고 잘 구별하는 distribution이 먼저 만들어집니다. 이후 G가 현재 discriminator가 구별하기 어려운 방향으로 학습을 하면 (c)와 같이 좀 더 $$p_g$$가 $$p_{data}$$와 가까워지게 되고 이런식으로 학습을 반복하다 보면 결국 $$p_g = p_{data}$$가 되어 discriminator가 둘을 전혀 구별하지 못하는 $$D(x) = \frac{1}{2}$$ 상태가 된다는 것입니다. 

