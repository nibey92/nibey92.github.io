---
layout: post
title: Recurent Neural Network
excerpt: "RNN의 구조에 대해 알아보자"
categories: [deep learning]
comments: true
---

이번 포스팅은 여러 블로그 글들을 참고하였습니다. 주로 참고한 블로그 글은 다음과 같습니다.
{: .notice}

 > [ratsgo's blog](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/)
 
 > [쉽게 읽는 프로그래밍](https://m.blog.naver.com/PostView.nhn?blogId=magnking&logNo=221311273459&proxyReferer=https%3A%2F%2Fwww.google.com%2F)


## RNN 이란

Recurent Neural Network가 지닌 가장 큰 특징은 데이터의 순서와 시간을 고려할 수 있다는 것입니다. 덕분에 RNN 은 나오자마자 sequntial data를 이용하는 분야에서 많은 사랑을 받았는데요, 특히 문장 번역이나 음성 분석에 많이 사용되었습니다. 

일반적인 신경망을 Feed-forward neural networks(FFNets) 라고 하는데요, FFNets에서는 데이터를 입력하면 데이터가 각 노드를 한번씩 지나가며 연산이 진행되고 출력값이 나오게 됩니다. 각 노드를 한번만 지나가게 된다는 것은 데이터의 순서, 시간 이란 측면을 고려하지 않는다고 할 수 있습니다. 

하지만 RNN의 경우는 hidden layer의 결과가 다시 같은 hidden layer 의 입력으로 들어가도록 연결되어 있습니다. 이때 이 입력 값을 `h_t` 라고 하겠습니다. 바로 이 `h_t` 값이 RNN이 순서와 시간을 고려할 수 있도록 하는 요소라고 할 수 있습니다.


## RNN의 기본구조
위에서 얘기한 RNN의 구조를 그림으로 살펴보겠습니다. 

![RNN_2]({{ site.url }}/img/rnn_new.jpg)


그림을 보면 input value `x_t`, output value `y_t` 외에 또 하나의 파라미터 hidden state value `h_t`가 있습니다. `h_t`가 바로 위에서 얘기했듯 RNN으로 하여금 데이터의 순서와 시간을 고려할 수 있도록 가능하게 하는 요소입니다. 각 time step에서 그 state에 해당하는 `h_t` 가 나오고 이 `h_t`는 다시 다음 state 에 영향을 끼칩니다. 그렇다면 어떤 계산으로 `$$h^t$$`가 나오는지 hidden layer 를 자세히 알아보도록 합시다.

## Hidden layer의 작동원리
Hidden layer의 구조를 보면 다음과 같이 나타낼 수 있습니다. 두개의 함수로 이루어 졌다고 생각할 수 있는대요 하나는 s_t를 생성하는 함수이고, 다른 하나는 y_t를 생성하는 함수입니다.
s_t를 생성하는 함수Fs, y_t를 생성하는 함수를 Fy라 하고 각각의 함수는 다음의 input를 받습니다. 이것을 다음과 같이 간단하게 식으로 나타내보면
Fs(x_t, s_(t-1)) = s_t 
Fy(s_t) = $y_t$

$y^x$

고쳣다


이렇게 볼 수 있습니다.

